\documentclass[dissertation.tex]{subfiles}
\begin{document}

\chapter{Evaluation}
\label{ch:eval}

\section{Objectives}
\Cref{ch:impl} defined the scope of this evaluation, and
discussed the compromises that were made to compile Rust's core
libraries for CHERI.

This chapter contains the main evaluation on the benefits and detriments
of porting Rust to CHERI.
The key questions this evaluation seeks to address are:

\begin{description}
    \item[\Cref{sec:eval-cheri}] What implications do Rust programs and a
    compilation toolchain have for CHERI?
    Specifically, how do Rust's unique characteristics---its borrow
    checker and lifetime model, temporal safety guarantees, small
    runtime---translate to a capability architecture?
    Do they complement or overlap the functionality provided by CHERI?
    \item[\Cref{sec:eval-rust}] What implications does running on a
    CHERI architecture have for Rust?
    More concretely, what are the safety and performance differences
    from running on other platforms such as x86 or MIPS?
    \item[\Cref{sec:eval-micro}] Can CHERI capabilities mitigate or prevent
    vulnerabilities in Rust, and what is the nature of these flaws?
    Do they manifest differently in Rust, and can they be mitigated by
    other means?
    If C equivalents for these flaws exist, what nature do they take and
    does CHERI behave similarly? \wip{rework}
    If equivalents in other safe languages exist\ldots
    \item[\Cref{sec:eval-othersafe}] What are the general concerns when
    porting a safe language to CHERI or other capability architectures?
    Generally, are safe languages easier to port to CHERI? Do they
    derive more benefit from capabilities than unsafe languages?
    \wip{Why hasn't anyone written about doing this?}
    \item[\Cref{sec:eval-betterunsafe}] How can the safety guarantees
    and boundaries of unsafe code be changed with the use of CHERI
    capabilities, or: do capabilities give rise to a different natural
    definition of unsafe code?
    What insight does this provide for language design and
    non-capability platforms?
\end{description}


\section{Benefits to CHERI as a Rust target}
\label{sec:eval-cheri}

\subsection{Ownership gives complementary temporal safety}
\label{sec:eval-cheri-spatial-temporal}

\todo{CHERI seems to focus on spatial safety. What about revocation and
temporal safety? How helpful are Rust lifetimes and ownership?}

One of Rust's main objectives and early selling points was
\emph{fearless concurrency}.
It uses its ownership model and type system to manage temporal memory
safety~\cite{rust-trpl-book}.
By contrast, CHERI's initial focus was on spatial integrity, only later
moving to consider temporal safety by means of tagging.
Temporal safety is provided by marking capabilities as \emph{local} or
\emph{global}, which restricts the flow of capabilities and thereby
preventing their leakage~\cite{cheri2015}.

However, this provision only yields atomic pointer updates and
identifiability of pointers;
it is not precise enough to guarantee safety across thread or process
boundaries, such as FFI and system calls~\cite{cheri-2019-abstract}.
While Rust does not provide temporal protection against other processes
misusing its resources, its ownership model guarantees that a thread
which has yielded a resource does not attempt to modify it while it has
been lent out.
Likewise, the ownership model prevents similar conflicts within a
concurrent Rust program, complementing CHERI's spatial integrity.

Note: \Cref{sec:eval-rust-xprocess} discusses how CHERI capabilities can
be used to make Rust's FFI or cross-process calls safer.


\subsection{Borrow semantics and object lifetimes}
\todo{Discuss provenance analysis and revocation.}


\subsection{Safer code patterns yields easier porting to CHERI}
\label{sec:eval-cheri-port}

Rust has been designed to guide programmers toward writing safe code,
and to highlight potentially dangerous operations.
Programmers have less cause to perform unusual or \emph{clever} pointer
manipulation, writing code that does not immediately compile for CHERI.
\wip{sec:impl-??} documented the limited incompatibilities in the core
library; most changes affect the compiler.
With a fully-functional Rust compiler for CHERI, porting Rust programs
and crates should be relatively straightforward.

Nevertheless, one should recognise that the difficulty of porting C
programs to capability architectures and CHERI in particular is not
thought to be too onerous~\cite{capsicum-usability}.
This must be weighed against the prospect of updating the Rust compiler.


\subsection{Comparable performance to C}
\label{eval:cheri-perf}

While Rust possesses strong safety features, it also provides good
performance.
For this reason, it has garnered attention in applications as diverse as
astrophysics (favourable comparison to Fortran~\cite{blanco-astro}), GPU
programming (comparable to handwritten and domain-specific language
generated OpenCL~\cite{holk-gpu}), and garbage collection (comparable to
C~\cite{lin-gc}).
The Debian project maintains a set of toy benchmarks run against
user-submitted programs in diverse
languages~\cite{debian-benchmarksgame}, showing that Rust performs as
well as C and C++ under their testing problems and environment.
All three come well ahead of the next `safe' languages, Java and Go.

These suggest that Rust is capable of matching C under some
circumstances while being safer, making it a good choice in general.
If CHERI implementers are keen on augmenting hardware safety features
with a speedy, low-runtime language, then Rust makes a sensible choice,
especially for embedded platforms.


\section{Benefits to Rust from CHERI capabilities}
\label{sec:eval-rust}

\subsection{Traditional vulnerabilities in Rust}
\label{sec:eval-rust-vulns}

One class of attacks that Rust aims to mitigate is buffer overflows.
In Safe Rust, bounds checks are inserted (\Cref{sec:bg-rust-bounds})
to prevent out-of-bounds accesses and writes.

Nevertheless, as \Cref{sec:rust-unsafe} highlights, unchecked accesses
are sometimes used for optimisation, by reading or writing using raw
pointers.
These unsafe operations are just as susceptible to programmer errors as
their C analogues, giving rise to the bugs discussed in
\Cref{sec:eval-micro-repeat,sec:eval-micro-push}.
Capabilities can combat this by preventing out-of-bounds accesses.


\subsection{Removal of bounds checks}
\label{sec:eval-rust-bounds}

With capabilities, bounds checks can be removed altogether: instead of
the default panic, a hardware interrupt will occur with each attempted
out-of-bounds access.
Most Rust programs do not handle panics, instead crashing the program:
this is the default behaviour.
If desired, CHERI length violations can be caught and the panic handler
invoked, rather than terminating the program directly.
Therefore the CHERI mechanism is fully compatible with the existing
panicking framework.

However, most bounds checks are elided with compiler optimisations
enabled.
\Cref{sec:rust-elision} gives some situations in which bounds checks are
optimised out (\Cref{lst:rust-iter-unchecked}).
However, they are unavoidable in some situations \wip{evidence}, such as
heap-allocated linked lists or tree structures, particularly relevant
for systems programming.


\subsection{Safety of FFI calls}
\label{sec:eval-rust-xprocess}

\todo{As explored in CHERI-JNI, but Rust checks structs at runtime.
Discuss sealed capabilities here.}


\subsection{Leaking and circular data structures}
\todo{\url{https://doc.rust-lang.org/nomicon/leaking.html} See Rc.}


\subsection{Unsafe semantics}
Not everything is unsafe any more? Dereferencing arbitrary pointers now
guaranteed to crash rather than leak.


\section{Microbenchmarks}
\label{sec:eval-micro}

\todo{Write something here?}

\todo{Structure the microbenchmarks: cause, evidence?, lessons?/how CHERI helps}


\subsection{Pushing to a \texttt{VecDeque}: off-by-one error leads to out-of-bounds write}
\label{sec:eval-micro-push}

Rust's \texttt{VecDeque} is a circular data structure stored on a
buffer.
When this buffer is expanded, elements stored at its (former) end must
be moved to its new end.
This error was caused by incorrect use of the public capacity, accessed
by \texttt{self.capacity()}, instead of the private (raw) capacity of
the buffer, \texttt{self.cap()}.
Subsequently, the pointer to the deque's \texttt{head} would point to
the address immediately after the buffer, rather than its start.

\todo{This can be solved by not getting confused, assertion on the
copying helper (potentially slow), deque indexing instead of pointers.}


\subsection{Slice \texttt{repeat}: integer overflow leads to buffer overflow}
\label{sec:eval-micro-repeat}

This flaw arose from an unchecked write, one pattern of optimisation
using Unsafe Rust covered in \Cref{sec:rust-unsafe}.
It occurs in the \texttt{repeat} function on slices
(\Cref{lst:slice-repeat}), which returns a vector containing a slice
repeated as specified by the parameter.
Here, a buffer overflow occurs when the length of returned vector would
exceed the target's \texttt{usize}.

\begin{figure}[ht]
\begin{lstlisting}
impl<T> [T] {
    pub fn repeat(&self, n: usize) -> Vec<T> where T: Copy {
        // omitted: trivial n = 0 case
        let mut buf = Vec::with_capacity(self.len() * n);

        buf.extend(self);
        {
            let mut m = n >> 1;
            while m > 0 {
                unsafe {
                    // memcpy existing elements to double the length
                }
            }
        }
        // omitted: copy into the remainder of the vector
    }
}
\end{lstlisting}
\caption{\wip{rewrite} Rust's slice \texttt{repeat}, from
\texttt{alloc::slice}. Parts omitted for brevity. This code will attempt
to write beyond the end of a buffer.
The error is in line~4; it was fixed by using a multiplication checked
against overflowing.}
\label{lst:slice-repeat}
\end{figure}

\todo{Think about this seriously. Is it at all practical? The obvious
case is the write is interrupted before the address falls of the maximum
value. Are there specific values that work for any platform?}

This is difficult to exploit, as it would require a long slice or a
large number \(n\) of repetitions, increasing the change of a
segmentation fault.
Nonetheless, it is certainly not thread-safe, and Rust does target
platforms with 16-bit \texttt{usize}, i.e.\ at most \(65,536\) elements,
making an attack plausible, if not possible.


\section{Porting safe languages to capability architectures}
\label{sec:eval-othersafe}


\section{Strengthening unsafety}
\label{sec:eval-betterunsafe}


\end{document}
