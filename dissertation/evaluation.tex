\documentclass[dissertation.tex]{subfiles}
\begin{document}

\chapter{Evaluation}
\label{ch:eval}

\section{Objectives}
\Cref{ch:impl} defined the scope of this evaluation, and
discussed the compromises that were made to compile Rust's core
libraries for CHERI.

This chapter contains the main evaluation on the benefits and detriments
of porting Rust to CHERI.
The key questions this evaluation seeks to address are:

\begin{description}
    \item[\Cref{sec:eval-cheri}] What implications do Rust programs and a
    compilation toolchain have for CHERI?
    Specifically, how do Rust's unique characteristics---its borrow
    checker and lifetime model, temporal safety guarantees, small
    runtime---translate to a capability architecture?
    Do they complement or overlap the functionality provided by CHERI?
    \item[\Cref{sec:eval-rust}] What implications does running on a
    CHERI architecture have for Rust?
    More concretely, what are the safety and performance differences
    from running on other platforms such as x86 or MIPS?
    \item[\Cref{sec:eval-bugs}] Can CHERI capabilities mitigate or prevent
    vulnerabilities in Rust, and what is the nature of these flaws?
    Do they manifest differently in Rust, and can they be mitigated by
    other means?
    If C equivalents for these flaws exist, what nature do they take and
    does CHERI behave similarly? \wip{rework}
    If equivalents in other safe languages exist\ldots
    \item[\Cref{sec:eval-othersafe}] What are the general concerns when
    porting a safe language to CHERI or other capability architectures?
    Generally, are safe languages easier to port to CHERI? Do they
    derive more benefit from capabilities than unsafe languages?
    \wip{Why hasn't anyone written about doing this?}
    \item[\Cref{sec:eval-betterunsafe}] How can the safety guarantees
    and boundaries of unsafe code be changed with the use of CHERI
    capabilities, or: do capabilities give rise to a different natural
    definition of unsafe code?
    What insight does this provide for language design and
    non-capability platforms?
\end{description}


\section{Errors leading to memory violations in Rust}
\label{sec:eval-bugs}

Despite Rust's attention to safe language design, programmer error is
still a rich source of potential vulnerabilities.
While the Rust community is generally conscious about memory safety and
security, nowhere is this more true than with the language and compiler
developers.

This section covers five memory safety flaws discovered in the Rust
compiler and standard library, all preventable with CHERI capabilities.
Where relevant, demonstrative microbenchmarks were performed on either
CheriBSD on Qemu-CHERI with 128-bit capabilities, or FreeBSD~11.2
(amd64) for the non-capability comparison.
In all cases, the Rust compiler was as described in
\Cref{ch:rust,ch:impl}, specifying the target as appropriate.


\subsection{Pushing to a \texttt{VecDeque}: off-by-one error leads to out-of-bounds write}
\label{sec:eval-micro-push}

\subsubsection{Cause}
Rust's \texttt{VecDeque} is a circular data structure stored on a
buffer.
When this buffer is expanded, elements stored at its (former) end must
be moved to its new end.
This error was caused by incorrectly using the public capacity, accessed
by \texttt{self.capacity()}, instead of the private (raw) capacity of
the buffer, \texttt{self.cap()}
(\Cref{lst:deque-defs})~\cite{rust-pr-reserve,rust-issue-deque-append}.

\begin{figure}[ht]
    \lstinputlisting{listings/deque-defs.rs}
    \caption{
        The public-facing definitions for a \texttt{VecDeque}'s
        capacity, and pushing to the end.
        It will not escape the reader's attention that the
        \texttt{capacity} might be mistaken for the \texttt{cap}, a
        likely cause of this error.
        These definitions are still current in Rust's built-in data
        structures.
        \texttt{push\_back} annotated with implicit precondition.
    }
    \label{lst:deque-defs}
\end{figure}

Subsequently, the pointer to the deque's \texttt{head} would point to
the address immediately after the buffer, rather than its start.
Pushing to the back of the deque then attempts to write to the address
after the buffer, rather than within it.

\subsubsection{Demonstration microbenchmark}
I checked that this spatial violation is caught by CHERI capabilities,
but is not detected on x86 FreeBSD.
Sample code is shown in \Cref{lst:micro-capacity}.

\begin{figure}[ht]
    \lstinputlisting{listings/micro-capacity.rs}
    \caption{
        A program which writes beyond the end of an allocated
        \texttt{VecDeque} buffer.
        An off-by-one error in \texttt{reserve} results in an unsound
        call another function, updating \texttt{head} to 32.
        Under x86 without capabilities, the program terminates normally,
        printing output as shown in the comments.
        With CHERI capabilities, execution continues until line~12, which
        traps due to a length violation.
    }
    \label{lst:micro-capacity}
\end{figure}

Had another data structure been allocated after the deque, its start
would have been overwritten by the pushed element.
However, I was unable to force this situation without modifying the
allocator for the purpose.

\subsubsection{Observations}
This scenario is a plain example of a bounds violation that can be
prevented using capabilities.
Had the underlying implementation not used an unchecked write (line 12
of \Cref{lst:deque-defs}), this would also have been prevented by Rust's
bounds checks, as the \texttt{VecDeque} is backed by a vector.
This is an interesting lesson: bounds checks are useful not only for the
end-programmer, but also (presumably meticulous) language developers.

\todo{This is also detected by ASAN (bother writing?)}

Note that whether this exceeds the bounds is implementation specific!
The existing implementation will reserve space for 32 elements here, but
if more space had been reserved by \texttt{with\_capacity} or its
underlying code (e.g.\ 64 elements), the object bounds would have been
correspondingly wider.
In that case, it would only be detected if the value was written using
the built-in bounds-checking indexing, although the pushed value would
still disappear.


\subsection{Slice \texttt{repeat}: integer overflow leads to buffer overflow}
\label{sec:eval-micro-repeat}

\subsubsection{Cause}
This flaw arose from an unchecked write, one pattern of optimisation
using Unsafe Rust covered in \Cref{sec:rust-unsafe}.
It occurs in the \texttt{repeat} function on slices
(\Cref{lst:slice-repeat}), which returns a vector containing a slice
repeated as specified by the parameter.
Here, a buffer overflow occurs when the length of returned vector would
exceed the target's \texttt{usize}.

\begin{figure}[ht]
    \lstinputlisting{listings/slice-repeat.rs}
    \caption{
        \wip{rewrite}
        Rust's slice \texttt{repeat}, from \texttt{alloc::slice}.
        Parts omitted for brevity.
        This code attempts to write beyond the end of a buffer.
        The error is in line~4; it was fixed by checking the
        multiplication against integer overflow.
    }
    \label{lst:slice-repeat}
\end{figure}

\subsubsection{Demonstration microbenchmark}
I did not demonstrate this by calling the \texttt{repeat} method as
given: as noted below, attempting to copy more than \(2^{64}\) elements
is difficult to do in a controlled way.
Instead, \Cref{lst:micro-repeat} shows the code used to demonstrate the
effects of this bug.

\begin{figure}[ht]
    \lstinputlisting{listings/micro-repeat.rs}
    \caption{
        \wip{this whole fig}
    }
    \label{lst:micro-repeat}
\end{figure}

I chose values carefully to demonstrate the overflow on the test
machine; other values may work depending on the operating system and
allocator.

\subsubsection{Observations}
\todo{Think about this seriously. Is it at all practical? The obvious
case is the write is interrupted before the address falls of the maximum
value. Are there specific values that work for any platform?}

This is difficult to exploit, as it would require a long slice or a
large number \(n\) of repetitions, increasing the change of a
segmentation fault.
Nonetheless, it is certainly not thread-safe, and Rust does target
platforms with 16-bit \texttt{usize}, i.e.\ at most \(65,536\) elements,
making an attack plausible, if not possible.


\subsection{Out-of-bounds indexing into a reversed slice}

\subsection{\texttt{Vec} method violates Rust's uniqueness of shared references}

\subsection{Uncaught move of implicitly-immutable value}
\todo{Rephrase title}


\section{Benefits to CHERI as a Rust target}
\label{sec:eval-cheri}

\subsection{Ownership gives complementary temporal safety}
\label{sec:eval-cheri-spatial-temporal}

\todo{CHERI seems to focus on spatial safety. What about revocation and
temporal safety? How helpful are Rust lifetimes and ownership?}

One of Rust's main objectives and early selling points was
\emph{fearless concurrency}.
It uses its ownership model and type system to manage temporal memory
safety~\cite{rust-trpl-book}.
By contrast, CHERI's initial focus was on spatial integrity, only later
moving to consider temporal safety by means of tagging.
Temporal safety is provided by marking capabilities as \emph{local} or
\emph{global}, which restricts the flow of capabilities and thereby
preventing their leakage~\cite{cheri2015}.

However, this provision only yields atomic pointer updates and
identifiability of pointers;
it is not precise enough to guarantee safety across thread or process
boundaries, such as FFI and system calls~\cite{cheri-2019-abstract}.
While Rust does not provide temporal protection against other processes
misusing its resources, its ownership model guarantees that a thread
which has yielded a resource does not attempt to modify it while it has
been lent out.
Likewise, the ownership model prevents similar conflicts within a
concurrent Rust program, complementing CHERI's spatial integrity.

Note: \Cref{sec:eval-rust-xprocess} discusses how CHERI capabilities can
be used to make Rust's FFI or cross-process calls safer.


\subsection{Borrow semantics and object lifetimes}
\todo{Discuss provenance analysis and revocation.}


\subsection{Safer code patterns yields easier porting to CHERI}
\label{sec:eval-cheri-port}

Rust has been designed to guide programmers toward writing safe code,
and to highlight potentially dangerous operations.
Programmers have less cause to perform unusual or \emph{clever} pointer
manipulation, writing code that does not immediately compile for CHERI.
\wip{sec:impl-??} documented the limited incompatibilities in the core
library; most changes affect the compiler.
With a fully-functional Rust compiler for CHERI, porting Rust programs
and crates should be relatively straightforward.

Nevertheless, one should recognise that the difficulty of porting C
programs to capability architectures and CHERI in particular is not
thought to be too onerous~\cite{capsicum-usability}.
This must be weighed against the prospect of updating the Rust compiler.


\subsection{Comparable performance to C}
\label{eval:cheri-perf}

While Rust possesses strong safety features, it also provides good
performance.
For this reason, it has garnered attention in applications as diverse as
astrophysics (favourable comparison to Fortran~\cite{blanco-astro}), GPU
programming (comparable to handwritten and domain-specific language
generated OpenCL~\cite{holk-gpu}), and garbage collection (comparable to
C~\cite{lin-gc}).
The Debian project maintains a set of toy benchmarks run against
user-submitted programs in diverse
languages~\cite{debian-benchmarksgame}, showing that Rust performs as
well as C and C++ under their testing problems and environment.
All three come well ahead of the next `safe' languages, Java and Go.

These suggest that Rust is capable of matching C under some
circumstances while being safer, making it a good choice in general.
If CHERI implementers are keen on augmenting hardware safety features
with a speedy, low-runtime language, then Rust makes a sensible choice,
especially for embedded platforms.


\section{Benefits to Rust from CHERI capabilities}
\label{sec:eval-rust}

\subsection{Traditional vulnerabilities in Rust}
\label{sec:eval-rust-vulns}

One class of attacks that Rust aims to mitigate is buffer overflows.
In Safe Rust, bounds checks are inserted (\Cref{sec:bg-rust-bounds})
to prevent out-of-bounds accesses and writes.

Nevertheless, as \Cref{sec:rust-unsafe} highlights, unchecked accesses
are sometimes used for optimisation, by reading or writing using raw
pointers.
These unsafe operations are just as susceptible to programmer errors as
their C analogues, giving rise to the bugs discussed in
\Cref{sec:eval-micro-repeat,sec:eval-micro-push}.
Capabilities can combat this by preventing out-of-bounds accesses.


\subsection{Removal of bounds checks}
\label{sec:eval-rust-bounds}

With capabilities, bounds checks can be removed altogether: instead of
the default panic, a hardware interrupt will occur with each attempted
out-of-bounds access.
Most Rust programs do not handle panics, instead crashing the program:
this is the default behaviour.
If desired, CHERI length violations can be caught and the panic handler
invoked, rather than terminating the program directly.
Therefore the CHERI mechanism is fully compatible with the existing
panicking framework.

However, most bounds checks are elided with compiler optimisations
enabled.
\Cref{sec:rust-elision} gives some situations in which bounds checks are
optimised out (\Cref{lst:rust-iter-unchecked}).
However, they are unavoidable in some situations, such as random array
accesses.


\subsection{Enforcing immutability with capabilities}
\label{sec:eval-rust-enforce-immut}

Modifying an immutable object is undefined behaviour in Rust, and should
be prevented by the compiler in Safe Rust.
The only exception to this pattern seems to be the \texttt{UnsafeCell},
which is excluded from being UB.
There, the programmer is expected to implement an object safely without
causing concurrency bugs.

\clar{Expound on these bugs?}

There have been bugs in the compiler~\cite{rust-issue-match-borrow} and
standard library~\cite{rust-issue-vec-mut} resulting in mutable
references to supposedly immutable objects.
Since mutating them is undefined, it would be reasonable to protect them
from being written to, which can be accomplished with capabilities.
This enforces the principle of least privilege on shared references.

This can be done by deriving a non-writeable capability for every shared
reference.
I propose that the borrow checker continue to be used to prevent the
holder of the original reference from mutating the object: this is the
current behaviour, would avoid uncertainty over when an object could be
written to again, and is not known to be a source of past errors.

\subsubsection{Caveat}
However, manipulating capabilities is not free and the overheads of this
approach should be weighed against the existing type system.
Additionally, this does not solve the inherent potential for programmer
error in the compiler, as seen in the match arm bug where the value is
only implicitly immutable.

\subsubsection{Note on differences from C}
Enforcing C's \texttt{const} in hardware proved problematic for CHERI in
the past, due to functions like~\texttt{strchr} (C), which derive a
non-\texttt{const} (mutable) pointer from an immutable one.

\begin{lstlisting}[language=C]
char *strchr(const char *s, int c);
\end{lstlisting}

The proposal of deriving a read-only capability for each immutable
reference in Rust does not suffer this problem, as it is not possible to
derive a mutable reference from an immutable one.
Indeed, this idiom does not occur in Rust as immutability is conveyed by
the function signature.


\subsection{Preventing use-after-free in Safe Rust}
\label{sec:eval-rust-use-after-free}

As we have discovered, spatial integrity is not an absolute guarantee in
Rust.
Unsurprisingly, neither is temporal safety, even in \emph{Safe} Rust!

Consider the following example from the documentation, a simplified
version of the reference-counted container type, \texttt{Rc}, and its
simplified \texttt{Drop} implementation (\Cref{lst:eval-rust-rc-drop}).
By overflowing the reference count (using \texttt{mem::forget} if memory
usage is an issue), one can cause the pointed-to object to be
deallocated, even with outstanding references, defeating the reference
counter.
This creates a use-after-free bug~\cite{rust-nomicon-rc-leak}.

\begin{figure}[ht]
    \lstinputlisting{listings/rc-drop.rs}
    \caption{
        A potential use-after-free bug, if \texttt{ref\_count}
        overflows.
        This may occur in Safe Rust, as \texttt{drop} methods are always
        safe: the unsafety is encapsulated here, and so is
        \texttt{mem::forget}, which would be used to help overflow the count.
        Example from the Rust documentation~\cite{rust-nomicon-rc-leak}.
    }
    \label{lst:eval-rust-rc-drop}
\end{figure}

This can be resolved by revocation, which CHERI does not inherently
implement, but operating systems might implement on top of CHERI.
As there are limitations to this approach, both to the granularity of
revocations and the performance implications~\cite{cheri-v6}, this
should be considered a mitigation rather than a solution.


\subsection{Safety of FFI calls}
\label{sec:eval-rust-xprocess}

\todo{``Some of this is seen-similar''}

A quick survey of Rust crates that use FFI bindings shows that most of
them deal with some form of low-level behaviour, including encryption,
memory allocation, USB interfaces, and filesystem mounts.\footnote{
    Rust crates are published libraries.
    The reader may be interested to peruse a selection of crates at
    \url{https://crates.io/search?q=-sys};
    a \texttt{-sys} suffix conventionally denotes an FFI crate.
    \texttt{crates.io} is advertised as the ``Rust Package Registry''.
}
With performance or low-level access as the primary goal of most Rust
FFI calls, safety may not be a major concern, even if it could allow
arbitrary code execution in the Rust
program~\cite{szekeres-eternal-war}.

\subsubsection{Enforcing immutability across FFI boundaries}
The modification of an immutable object is a source of undefined
behaviour in Rust.
This is normally enforced by type-checking, but this is impossible
across a foreign function interface, since objects can only be passed
using raw pointers, and the function signatures are not known to the
Rust program.

By passing a capability without write permissions to a function, this
particular cause of undefined behaviour can be eliminated.
This supports the use of \emph{least privilege} even across FFI
boundaries.
This is an FFI-analogue of \Cref{sec:eval-rust-enforce-immut}.

\subsubsection{Sealed capabilities and callbacks}
Another situation that benefits from least privilege are callbacks from
FFI code.
In this scenario, an FFI function might ordinarily receive a pointer to
data which it might pass on via a callback, but have no need to inspect
or mutate.

This can be enforced through \emph{capability sealing}, which CHERI
provides for.
The C function would be unable to dereference the object, but the
callback function could, through some static method, unseal the
capability to regain access to the original data~\cite{cheri-v6}.
This could also allow less trusted code to handle Rust objects while
still guaranteeing integrity and confidentiality.

\subsubsection{Use-after-free through FFI}
The use of FFI functions can bypass Rust's object lifetime model, as
there is no way to ensure that an FFI function has not stored or leaked
references to borrowed Rust objects.
This can lead to later temporal unsoundness in the Rust program.

While this cannot be completely prevented with capabilities as-is,
\Cref{sec:eval-betterunsafe} discusses the potential to use revocations
to manage this risk.

\subsubsection{Overflowing object boundaries}
\clar{Demonstration microbenchmark?}

Objects can only be passed to C as raw pointers.
As such, a buffer overflow through an FFI function is no more difficult
than in C natively, and no less serious.

A simple example of an overflow opportunity uses the well-known source
of overflows which is a C string with a missing NUL terminating byte.
To overcome this, Rust strings instead store a length value and a byte
array, making them non-interchangeable with C strings.
This means, however, if that a programmer neglects to convert between
the formats, passing a Rust string to a C function will quickly lead to
an overflow.

Object capabilities easily protect against this by storing object
bounds.


\subsection{Unsafe semantics}
Not everything is unsafe any more? Dereferencing arbitrary pointers now
guaranteed to crash rather than leak.


\section{Porting safe languages to capability architectures}
\label{sec:eval-othersafe}

\todo{Think about (categorise?) these:}
\begin{itemize}
    \item What are the major existing problems with the language?
    \item Existing vulnerabilities?
    \item What guarantees does the language provide?
    \item Where does it derive its safety from? Some type systems may
    have overheads that cannot be easily reduced.
    \item Is Cython still Python?
    \item Do you make code invalid? e.g.\ can no longer get change a
    const ptr to a mut ptr? memchr strikes again
    \item Assumptions about address spaces and pointers---do they
    already use fat/smart pointers?
    \item Are there multiple runtime implementations?
\end{itemize}


\section{Strengthening unsafety}
\label{sec:eval-betterunsafe}


\end{document}
