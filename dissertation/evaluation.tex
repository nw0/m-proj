\documentclass[dissertation.tex]{subfiles}
\begin{document}

\chapter{Evaluation}
\label{ch:eval}

\section{Objectives}
\Cref{ch:impl} defined the scope of this evaluation, and
discussed the compromises that were made to compile Rust's core
libraries for CHERI.

This chapter contains the main evaluation on the benefits and detriments
of porting Rust to CHERI.
The key questions this evaluation seeks to address are:

\begin{description}
    \item[\Cref{sec:eval-cheri}] What implications do Rust programs and a
    compilation toolchain have for CHERI?
    Specifically, how do Rust's unique characteristics---its borrow
    checker and lifetime model, temporal safety guarantees, small
    runtime---translate to a capability architecture?
    Do they complement or overlap the functionality provided by CHERI?
    \item[\Cref{sec:eval-rust}] What implications does running on a
    CHERI architecture have for Rust?
    More concretely, what are the safety and performance differences
    from running on other platforms such as x86 or MIPS?
    \item[\Cref{sec:eval-bugs}] Can CHERI capabilities mitigate or prevent
    vulnerabilities in Rust, and what is the nature of these flaws?
    Do they manifest differently in Rust, and can they be mitigated by
    other means?
    If C equivalents for these flaws exist, what nature do they take and
    does CHERI behave similarly? \wip{rework}
    If equivalents in other safe languages exist\ldots
    \item[\Cref{sec:eval-othersafe}] What are the general concerns when
    porting a safe language to CHERI or other capability architectures?
    Generally, are safe languages easier to port to CHERI? Do they
    derive more benefit from capabilities than unsafe languages?
    \wip{Why hasn't anyone written about doing this?}
    \item[\Cref{sec:eval-betterunsafe}] How can the safety guarantees
    and boundaries of unsafe code be changed with the use of CHERI
    capabilities, or: do capabilities give rise to a different natural
    definition of unsafe code?
    What insight does this provide for language design and
    non-capability platforms?
\end{description}


\section{Errors leading to memory violations in Rust}
\label{sec:eval-bugs}

Despite Rust's attention to safe language design, programmer error is
still a rich source of potential vulnerabilities.
While the Rust community is generally conscious about memory safety and
security, nowhere is this more true than with the language and compiler
developers.

This section covers five memory safety flaws discovered in the Rust
standard library, all preventable with CHERI capabilities.
Where relevant, demonstrative microbenchmarks were performed on either
CheriBSD on Qemu-CHERI with 128-bit capability pointers, or FreeBSD~11.2
(amd64) for the non-capability comparison.
In all cases, the Rust compiler was as described in
\Cref{ch:rust,ch:impl}, specifying the target as appropriate.


\subsection{Pushing to a \texttt{VecDeque}: off-by-one error leads to out-of-bounds write}
\label{sec:eval-micro-push}

\subsubsection{Cause}
Rust's \texttt{VecDeque} is a circular data structure stored on a
buffer.
When this buffer is expanded, elements stored at its (former) end must
be moved to its new end.
This error was caused by incorrectly using the public capacity, accessed
by \texttt{self.capacity()}, instead of the private (raw) capacity of
the buffer, \texttt{self.cap()}
(\Cref{lst:deque-defs})~\cite{rust-pr-reserve,rust-issue-deque-append}.

\begin{figure}[ht]
    \lstinputlisting{listings/deque-defs.rs}
    \caption{
        The public-facing definitions for a \texttt{VecDeque}'s
        capacity, and pushing to the end.
        It will not escape the reader's attention that the
        \texttt{capacity} might be mistaken for the \texttt{cap}, a
        likely cause of this error.
        These definitions are still current in Rust's built-in data
        structures.
        \texttt{push\_back} annotated with implicit precondition.
    }
    \label{lst:deque-defs}
\end{figure}

Subsequently, the pointer to the deque's \texttt{head} would point to
the address immediately after the buffer, rather than its start.
Pushing to the back of the deque then attempts to write to the address
after the buffer, rather than within it.

\subsubsection{Demonstration microbenchmark}
I checked that this spatial violation is caught by CHERI capabilities,
but is not detected on x86 FreeBSD.
Sample code is shown in \Cref{lst:micro-capacity}.

\begin{figure}[ht]
    \lstinputlisting{listings/micro-capacity.rs}
    \caption{
        A program which writes beyond the end of an allocated
        \texttt{VecDeque} buffer.
        An off-by-one error in \texttt{reserve} results in an unsound
        call another function, updating \texttt{head} to 32.
        Under x86 without capabilities, the program terminates normally,
        printing output as shown in the
        comments.{\protect\textsuperscript\textdagger}
        With CHERI capabilities, execution continues until line~12, which
        traps due to a length violation.
        \\ {\footnotesize \protect\textdagger\ The \texttt{prntf!} macro
        is \emph{not} built-in; I define it for convenience. See
        \cref{foot:prntf} on \cpageref{foot:prntf}.}
    }
    \label{lst:micro-capacity}
\end{figure}

Had another data structure been allocated after the deque, its start
would have been overwritten by the pushed element.
However, I was unable to force this situation without modifying the
allocator for the purpose.

\subsubsection{Observations}
This scenario is a plain example of a bounds violation that can be
prevented using capabilities.
Had the underlying implementation not used an unchecked write (line 12
of \Cref{lst:deque-defs}), this would also have been prevented by Rust's
bounds checks, as the \texttt{VecDeque} is backed by a vector.
This is an interesting lesson: bounds checks are useful not only for the
end-programmer, but also (presumably meticulous) language developers.

Note that whether this exceeds the bounds is implementation specific!
The existing implementation will reserve space for 32 elements here, but
if more space had been reserved by \texttt{with\_capacity} or its
underlying code (e.g.\ 64 elements), the object bounds would have been
correspondingly wider.
In that case, it would only be detected if the value was written using
the built-in bounds-checking indexing, although the pushed value would
still disappear.


\subsection{Slice \texttt{repeat}: integer overflow leads to buffer overflow}
\label{sec:eval-micro-repeat}

\subsubsection{Cause}
This flaw arose from an unchecked write, one pattern of optimisation
using Unsafe Rust covered in \Cref{sec:rust-unsafe}.
It occurs in the \texttt{repeat} function on slices
(\Cref{lst:slice-repeat}), which returns a vector containing a slice
repeated as specified by the parameter.
Here, a buffer overflow occurs when the length of returned vector would
overflow the target's \texttt{usize}.

\begin{figure}[ht]
    \lstinputlisting{listings/slice-repeat.rs}
    \caption{
        Rust's slice \texttt{repeat}, from \texttt{alloc::slice}.
        Part omitted for brevity.
        This code attempts to write beyond the end of a buffer.
        The error is in line~5; it was fixed by checking the
        multiplication against integer overflow.
    }
    \label{lst:slice-repeat}
\end{figure}

\subsubsection{Demonstration microbenchmark}
I did not demonstrate this by calling the \texttt{repeat} method as
given: as noted below, attempting to copy more than \(2^{64}\) elements
is difficult to do in a controlled way.
Instead, \Cref{lst:micro-repeat} shows the code used to demonstrate the
effects of this bug.

\begin{figure}[ht]
    \lstinputlisting{listings/micro-repeat.rs}
    \caption{
        Demonstration of how an integer overflow can lead to a buffer
        overflow when repeating a slice.
        Three iterations of the copy are performed (lines 20--31) to
        ensure \texttt{v} is overwritten on the non-capability machine;
        with capabilities this traps on the first iteration.
    }
    \label{lst:micro-repeat}
\end{figure}

I chose values carefully to demonstrate the overflow on the test
machine; other values may work depending on the operating system and
allocator.

\subsubsection{Observations}
This is difficult to exploit, as it would require a long slice or a
large number \(n\) of repetitions, increasing the chance of a
segmentation fault.
An exploit would probably have to interrupt the write before too many
iterations of the loop, and either spawn a new process or stop the
thread executing this loop before the operating system stopped it.


\subsection{Out-of-bounds indexing into a reversed slice}

\subsubsection{Cause}
An unhandled unsigned integer wrap-around could lead to out-of-bounds
slice indexing through its reverse iterator~\cite{rust-pr-reverse}.
\Cref{lst:bug-reverse} shows the relevant implementation, defined in the
core library.

\begin{figure}[ht]
    \lstinputlisting{listings/bug-reverse.rs}
    \caption{
        Previous implementation of indexing into a reversed slice.
        If \texttt{amt - index - 1 < 0}, the index wraps, attempting to
        access an index larger than the indexable region.
        This may be unsafe depending on the underlying implementation.
        This was fixed by checking that \texttt{amt > index} before
        indexing, returning \texttt{None}
        otherwise~\cite{rust-commit-reverse}.
    }
    \label{lst:bug-reverse}
\end{figure}

\subsubsection{Observations}
A very large index (i.e.\ close to \texttt{usize::MAX}) could be passed
to the reverse indexing function to get values slightly beyond the end
of the slice.
As `slice' suggests, they frequently represent a view into a larger
slice, so this could reasonably be expected to be defined.

Whether this is possible is implementation-dependent; if the
reverse \texttt{idx} is expected to handle bad values, then the
underlying \texttt{idx} should arguably also handle them.
If anything, this example  and its resolution is an example of the
safety awareness of Rust developers, rather than a fundamental bug.


\subsection{Iterator method violates Rust's uniqueness of shared references}
\label{sec:eval-bug-vec-mut}

\subsubsection{Cause}
An iterator method in the core library should return a mutable slice
from a mutable iterator.
Instead, it returns a mutable slice for any iterator.
\Cref{lst:bug-mutslice} shows that it does this by calling an unsafe
method which operates on raw pointers~\cite{rust-issue-vec-mut}.

\begin{figure}[ht]
    \lstinputlisting{listings/bug-as_mut_slice.rs}
    \caption{
        Built-in method returning a mutable slice for a (mutable)
        iterator: except it accepts immutable iterators also.
        This violates Rust's temporal guarantee that mutable references
        are never shared.
    }
    \label{lst:bug-mutslice}
\end{figure}

\subsubsection{Observations}
This is a clear violation of one of Rust's temporal safety guarantees,
that mutable references must not ordinarily be shared.
While this is not strictly undefined behaviour, attempting to mutate the
returned object is, defeating the point of getting a mutable slice.

This appears to be bug caused by copying and pasting the Iterator
\texttt{as\_slice} method when writing \texttt{as\_mut\_slice}.
Again demonstrating the fallibility of programmers and motivating safe
syntax, neither the language nor the runtime helps in this situation.

Though this error leads to temporal unsafety, this could be prevented by
passing a read-only capability for an immutable borrow.
\Cref{sec:eval-rust-enforce-immut} discusses this in more detail.


\section{Benefits to CHERI as a Rust target}
\label{sec:eval-cheri}

Capabilities are typically seen as a mechanism to improve the security
of languages and runtimes.
It is therefore slightly unusual to consider how a language might
improve capabilities.
Nevertheless, this section considers how Rust complements CHERI
capabilities, presenting a contrast to other safe languages.

\subsection{Ownership gives complementary temporal safety}
\label{sec:eval-cheri-spatial-temporal}

One of Rust's main objectives and early selling points was
\emph{fearless concurrency}.
It uses its ownership model and type system to manage temporal memory
safety~\cite{rust-trpl-book}.
These mechanisms prevent dangling pointers or use-after-free in Safe
Rust (\Cref{sec:rust-borrow}), although the use of raw pointers in
Unsafe Rust can bypass these checks.

By contrast, CHERI's initial focus was on spatial integrity, only later
moving to consider temporal safety by means of tagging.
Temporal safety is provided by marking capabilities as \emph{local} or
\emph{global}, which restricts the flow of capabilities and thereby
preventing their leakage~\cite{cheri2015}.

However, this provision only yields atomic pointer updates and
identifiability of pointers;
it is not precise enough to guarantee safety across thread or process
boundaries, such as FFI and system calls~\cite{cheri-2019-abstract}.
While Rust does not provide temporal protection against other processes
misusing its resources, its ownership model guarantees that a thread
which has yielded a resource does not attempt to modify it while it has
been lent out.
Likewise, the ownership model prevents similar conflicts within a
concurrent Rust program, complementing CHERI's spatial integrity.

Note: \Cref{sec:eval-rust-xprocess} discusses how CHERI capabilities can
be used to make Rust's FFI or cross-process calls safer.

\subsubsection{Temporal safety under CHERI}
\todo{How much can I write about sweeping revocation in CHERI? + provenance analysis. Some of this might be moved to Rust benefits. Note this is a runtime overhead, but one that is (possibly?) reduced by lifetimes.}


\subsection{Safer code patterns yields easier porting to CHERI}
\label{sec:eval-cheri-port}

Rust has been designed to guide programmers toward writing safe code,
and to highlight potentially dangerous operations.
Programmers have less cause to perform unusual or \emph{clever} pointer
manipulation, writing code that does not immediately compile for CHERI.
\wip{sec:impl-??} documented the limited incompatibilities in the core
library; most changes affect the compiler.

With a fully-functional Rust compiler for CHERI, porting Rust programs
and crates should be relatively straightforward.
For example, common compatibility issues in CHERI due to pointer
provenance~\cite{cheri-2019-abstract} do not apply in Safe Rust,
apart from pointer shape (solely a compiler issue; see
\Cref{sec:impl-width}).
This is relevant because these incompatible pointer manipulations either
require the use of Unsafe Rust for raw pointers, which gives up much of
the safety guarantees motivating the use of Rust in the first instance,
or are explicitly undefined behaviour in Rust, hence a non-issue.

Nevertheless, one should recognise that the difficulty of porting C
programs to capability architectures and CHERI in particular is not
thought to be too onerous~\cite{capsicum-usability}.
This must be weighed against the prospect of updating the Rust compiler.


\subsection{Comparable performance to C}
\label{eval:cheri-perf}

While Rust possesses strong safety features, it also provides good
performance.
For this reason, it has garnered attention in applications as diverse as
astrophysics (favourable comparison to Fortran~\cite{blanco-astro}), GPU
programming (comparable to handwritten and domain-specific language
generated OpenCL~\cite{holk-gpu}), and garbage collection (comparable to
C~\cite{lin-gc}).
The Debian project maintains a set of toy benchmarks run against
user-submitted programs in diverse
languages~\cite{debian-benchmarksgame}, showing that Rust performs as
well as C and C++ under their testing problems and environment.
All three come well ahead of the next `safe' languages, Java and Go.

These suggest that Rust is capable of matching C under some
circumstances while being safer, making it a good choice in general.
If CHERI implementers are keen on augmenting hardware safety features
with a speedy, low-runtime language, then Rust makes a sensible choice,
especially for embedded platforms.


\section{Benefits to Rust from CHERI capabilities}
\label{sec:eval-rust}

This section explores how memory safety can be improved in Rust by
introducing CHERI capabilities.
\todo{more: performance? semantics?}
Capabilities can reduce the variety of undefined behaviour, while not
affecting compiler assumptions: for instance, attempting to dereference
a dangling pointer is guaranteed to trap, rather than possibly
succeeding and accessing another object unintentionally.

\subsection{Traditional vulnerabilities in Rust}
\label{sec:eval-rust-vulns}

One class of attacks that Rust aims to mitigate is buffer overflows.
In Safe Rust, bounds checks are inserted (\Cref{sec:bg-rust-bounds})
to prevent out-of-bounds accesses and writes.

Nevertheless, as \Cref{sec:rust-unsafe} highlights, unchecked accesses
are sometimes used for optimisation, by reading or writing using raw
pointers.
These unsafe operations are just as susceptible to programmer errors as
their C analogues, giving rise to the bugs discussed in
\Cref{sec:eval-micro-repeat,sec:eval-micro-push}.
Capabilities can combat this by preventing out-of-bounds accesses.


\subsection{Removal of bounds checks}
\label{sec:eval-rust-bounds}

With capabilities, bounds checks can be removed altogether: instead of
the default panic, a hardware interrupt will occur with each attempted
out-of-bounds access.
Most Rust programs do not handle panics, instead crashing the program:
this is the default behaviour.
If desired, CHERI length violations can be caught and the panic handler
invoked, rather than terminating the program directly.
Therefore the CHERI mechanism is fully compatible with the existing
panicking framework.

However, most bounds checks are elided with compiler optimisations
enabled.
\Cref{sec:rust-elision} gives some situations in which bounds checks are
optimised out (\Cref{lst:rust-iter-unchecked}).
However, they are unavoidable in some situations, such as random array
accesses.


\subsection{Enforcing sub-array bounds}

In Rust, \emph{slices} can be created from continuous segments of an
iterable.
Slices can be passed to functions, only allowing them to refer to part
of an array, or a \emph{subslice}.
Using pointer manipulation, such a function could access indices of the
array which are not part of the slice.
This is not undefined behaviour as the pointer would point to a valid
part of the object, although it must be done in Unsafe Rust.

With CHERI capabilities, a subslice could be passed as a pointer with
bounds restricted to the relevant segment of the array.
It would then be impossible for a function to access the other elements
unexpectedly, again enforcing the principle of least privilege.


\subsection{Enforcing immutability with capabilities}
\label{sec:eval-rust-enforce-immut}

Modifying an immutable object is undefined behaviour in Rust, and should
be prevented by the compiler in Safe Rust.
The only exception to this pattern is the \texttt{UnsafeCell}, which is
excluded from being UB.
There, the programmer is expected to implement an object safely without
causing concurrency bugs.

There have been bugs in the standard library~\cite{rust-issue-vec-mut}
(\Cref{sec:eval-bug-vec-mut}) resulting in mutable references to
supposedly immutable objects.
Since mutating these is undefined, it is reasonable to protect them
from being written to, which can be accomplished with capabilities.
This enforces the principle of least privilege on shared references.

This can be done by deriving a non-writeable capability for every shared
reference.
I propose that the borrow checker continue to be used to prevent the
holder of the original reference from mutating the object: this is the
current behaviour, would avoid uncertainty over when an object could be
written to again, and is not known to be a source of past errors.
In any case, monotonicity means that the original permissions need to be
`remembered', as they cannot later be derived from the read-only
borrowed permission.

\subsubsection{Caveat}
However, manipulating capabilities is not free and the overheads of
manipulating capabilities should be weighed against enforcement within
the existing type system.
Additionally, this does not solve the inherent potential for programmer
error in the compiler.

\subsubsection{Note on differences from C}
Enforcing C's \texttt{const} in hardware proved problematic for CHERI in
the past, due to functions like~\texttt{strchr} (C), which derive a
non-\texttt{const} (mutable) pointer from an immutable
one~\cite{cheri-prog-guide}.

\begin{lstlisting}[language=C]
char *strchr(const char *s, int c);
\end{lstlisting}

The proposal of deriving a read-only capability for each immutable
reference in Rust does not suffer this problem, as it is not possible to
derive a mutable reference from an immutable one.
Indeed, this idiom does not occur in Rust as immutability is conveyed by
the function signature.


\subsection{Preventing use-after-free in Safe Rust}
\label{sec:eval-rust-use-after-free}

As we have discovered, spatial integrity is not an absolute guarantee in
Rust.
Unsurprisingly, neither is temporal safety, even in \emph{Safe} Rust!

Consider the following example from the documentation, a simplified
version of the reference-counted container type, \texttt{Rc}, and its
simplified \texttt{Drop} implementation (\Cref{lst:eval-rust-rc-drop}).
By overflowing the reference count (using \texttt{mem::forget} if memory
usage is an issue), one can cause the pointed-to object to be
deallocated, even with outstanding references, defeating the reference
counter.
This creates a use-after-free bug~\cite{rust-nomicon-rc-leak}.

\begin{figure}[ht]
    \lstinputlisting{listings/rc-drop.rs}
    \caption{
        A potential use-after-free bug, if \texttt{ref\_count}
        overflows.
        This may occur in Safe Rust, as \texttt{drop} methods are always
        safe: the unsafety is encapsulated here, and also in
        \texttt{mem::forget}, which would be used to overflow the count.
        Example from the Rust documentation~\cite{rust-nomicon-rc-leak}.
    }
    \label{lst:eval-rust-rc-drop}
\end{figure}

This can be resolved by revocation, which CHERI does not inherently
implement, but operating systems might implement on top of CHERI.
\wip{discuss revocation?}
As there are limitations to this approach, both to the granularity of
revocations and the performance implications~\cite{cheri-v6}, this
should be considered a mitigation rather than a solution.


\subsection{Safety of FFI calls}
\label{sec:eval-rust-xprocess}

A quick survey of Rust crates that use FFI bindings shows that most of
them deal with some form of low-level behaviour, including encryption,
memory allocation, USB interfaces, and filesystem mounts.\footnote{
    Rust crates are published libraries.
    The reader may be interested to peruse a selection of crates at
    \url{https://crates.io/search?q=-sys};
    a \texttt{-sys} suffix conventionally denotes an FFI crate.
    \texttt{crates.io} is advertised as the ``Rust Package Registry''.
}
With performance or low-level access as the primary goal of most Rust
FFI calls, safety may not be a major concern, even if it could allow
arbitrary code execution in the Rust
program~\cite{szekeres-eternal-war}.

Many of the following points apply to non-FFI code as well, although
their protection across domain boundaries is perhaps more significant as
FFI calls cannot be type- or borrow-checked.

\subsubsection{Enforcing immutability across FFI boundaries}
The modification of an immutable object is a source of undefined
behaviour in Rust.
This is normally enforced by type-checking, but this is impossible
across a foreign function interface, since objects can only be passed
using raw pointers, and the function signatures are not known to the
Rust program.

By passing a capability without write permissions to a function, this
particular cause of undefined behaviour can be eliminated.
This supports the use of \emph{least privilege} even across FFI
boundaries.
This is an FFI-analogue of \Cref{sec:eval-rust-enforce-immut}.

\subsubsection{Sealed capabilities and callbacks}
Another situation that benefits from least privilege are callbacks from
FFI code.
In this scenario, an FFI function might ordinarily receive a pointer to
data which it might pass on via a callback, but have no need to inspect
or mutate.

This can be enforced through \emph{capability sealing}, which CHERI
provides.
The C function would be unable to dereference the object, but the
callback function could, through some static method, unseal the
capability to regain access to the original data~\cite{cheri-v6}.
This could also allow less trusted code to handle Rust objects while
still guaranteeing integrity and confidentiality.

\subsubsection{Use-after-free through FFI}
The use of FFI functions can bypass Rust's object lifetime model, as
there is no way to ensure that an FFI function has not stored or leaked
references to borrowed Rust objects.
This can lead to later temporal unsoundness in the Rust program.

While this cannot be completely prevented with capabilities as-is,
\wip{ref} discusses the potential to use revocations
to manage this risk.

\subsubsection{Overflowing object boundaries}
\clar{Demonstration microbenchmark?}

Objects can only be passed to C as raw pointers.
As such, a buffer overflow through an FFI function is no more difficult
than in C natively, and no less serious.

A simple example of an overflow opportunity uses the well-known source
of overflows which is a C string with a missing NUL terminating byte.
To overcome this, Rust strings instead store a length value and a byte
array, making them non-interchangeable with C strings.
This means, however, if that a programmer neglects to convert between
the formats, passing a Rust string to a C function will quickly lead to
an overflow.

Object capabilities easily protect against this by storing and enforcing
object bounds.
Importantly, they protect the rest of the calling program's address
space, preventing a cross-domain call from accessing data which was not
explicitly passed to it.

\subsubsection{CHERI compartmentalisation}
\todo{write: faster than sandboxing, ability to restrict syscalls}


\section{Issues unchanged by CHERI capabilities and Rust}
\todo{Anything important? sub-object bounds?}


\section{Porting safe languages to capability architectures}
\label{sec:eval-othersafe}

\todo{Think about (categorise?) these:}
\begin{itemize}
    \item What are the major existing problems with the language?
    \item Existing vulnerabilities?
    \item What guarantees does the language provide?
    \item Where does it derive its safety from? Some type systems may
    have overheads that cannot be easily reduced.
    \item Is Cython still Python?
    \item Do you make code invalid? e.g.\ can no longer get change a
    const ptr to a mut ptr? memchr strikes again
    \item Assumptions about address spaces and pointers---do they
    already use fat/smart pointers?
    \item Are there multiple runtime implementations?
\end{itemize}


\section{Strengthening unsafety}
\label{sec:eval-betterunsafe}


\end{document}
